# ğŸ“š References

## ğŸ› ï¸ Concepts & Optimization

- [Understanding Gradient Accumulation â€” Lightning Blog](https://lightning.ai/blog/gradient-accumulation/)  
  Explains what gradient accumulation is, why it's needed (especially under memory constraints), and how it affects optimization.  
  Includes PyTorch-style code examples and diagrams. Helpful for tuning `gradient_accumulation_steps` in low-resource or large-model settings.